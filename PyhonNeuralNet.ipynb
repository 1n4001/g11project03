{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def getData(filePath):\n",
    "    data = np.genfromtxt(filePath, delimiter=',')\n",
    "    x, y = np.array(data[:,0:-1], dtype=float), np.array(data[:,-1],dtype=int)\n",
    "    y = y.reshape(1,len(y)).T\n",
    "    return x,y\n",
    "\n",
    "def splitInputOutput(data):\n",
    "    x, y = np.array(data[:,0:-1], dtype=float), np.array(data[:,-1],dtype=int)\n",
    "    y = y.reshape(1,len(y)).T\n",
    "    return x,y\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def make_sigmoid_prime(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "def trainNeuralNetArrays(weights, eta, epochs, activator, activator_prime):\n",
    "    n = len(weights)\n",
    "    layers = [None] * n\n",
    "    deltas = [None] * n\n",
    "    for j in range(epochs):\n",
    "        for i in range(n):\n",
    "            if i == 0: # Push our input into the first weight\n",
    "                layers[i] = activator(np.dot(X,weights[i]))\n",
    "            else: # Push previous layer into current later using weights_i\n",
    "                layers[i] = activator(np.dot(layers[i-1],weights[i]))\n",
    "        for i in reversed(range(n)):\n",
    "            if i == n-1: # The delta closest to our output is (y-t) -- or \"y - layers[i]\" in this case\n",
    "                deltas[i] = (y - layers[i])*activator_prime(np.dot(layers[i-1],weights[i]))\n",
    "            elif i > 0: # While were not the first or last delta use the d_i+1, weights_i+1, layers_i-1, weights_i\n",
    "                deltas[i] = deltas[i+1].dot(weights[i+1].T)*activator_prime(np.dot(layers[i-1],weights[i]))\n",
    "            else: # update d_0 using X instead of one of the layers\n",
    "                deltas[i] = deltas[i+1].dot(weights[i+1].T)*activator_prime(np.dot(X,weights[i]))\n",
    "        for i in reversed(range(n)): # Back propagation time, start at the last weight and move forward\n",
    "            if i != 0:  # testing !=0 so show we backpropogate back to front {else statement}\n",
    "                weights[i] += eta*layers[i-1].T.dot(deltas[i])\n",
    "            else:\n",
    "                weights[i] += eta*X.T.dot(deltas[i])\n",
    "        \n",
    "def transformTestData(x, syn0, syn1, func):\n",
    "    layer1_transform = func(np.dot(x,syn0))\n",
    "    return func(np.dot(layer1_transform,syn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our neural network trainer against a simple dataset: X will contain binary pairs and Y will be the XOR result of rows in X.  We will initialize a random dataset of 0's and 1's with length 20 for A and B (X) and XOR the result for our y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing K-fold cross validation, splits = 5\n",
      "    MSE:  0.000473691424228\n",
      "    MSE:  0.000402454142081\n",
      "    MSE:  0.00066181651387\n",
      "    MSE:  0.000532135327975\n",
      "    MSE:  0.000895891246303\n",
      "X_test:  [[ 1.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 0.  0.]\n",
      " [ 1.  1.]]\n",
      "Y_test:  [[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Y_pred:  [[ 0.01916215]\n",
      " [ 0.98792081]\n",
      " [ 0.01916215]\n",
      " [ 0.0201313 ]\n",
      " [ 0.01916215]]\n",
      "\n",
      "MSE against Test data:  0.000826370048276\n",
      "Accuracy:  0.982060612017\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "a = np.random.randint(0,2,20) # gen a bunch of random numbers either 0 or 1\n",
    "b = np.random.randint(0,2,20) # do it again\n",
    "c = a ^ b #set C to be the XOR result of A XOR B\n",
    "X, y = splitInputOutput(np.asmatrix([a,b,c]).T)\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=None, shuffle=False) #our dataset was already random, no need to shuffle\n",
    "\n",
    "lowest_mse = 1e8 #arbitrary high value\n",
    "lowest_syn0 = []\n",
    "lowest_syn1 = []\n",
    "\n",
    "lowest_synapses = None\n",
    "\n",
    "eta = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "print(\"Performing K-fold cross validation, splits = 5\")\n",
    "# do our cross validation with training data\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    np.random.seed(seed=42)\n",
    "    syn0 = 2*np.random.random((X_train.shape[1],X_train.shape[0])) - 1\n",
    "    syn1 = 2*np.random.random((y_train.shape[0],y_train.shape[1])) - 1\n",
    "    synapses = [syn0, syn1]\n",
    "    \n",
    "    trainNeuralNetArrays(synapses, eta, epochs, lambda x: sigmoid(x), lambda x: sigmoid(x)*(1-sigmoid(x)))\n",
    "\n",
    "    for i in range(len(synapses)):\n",
    "        if i==0:\n",
    "            result = sigmoid(np.dot(X_test,synapses[i]))\n",
    "        else:\n",
    "            result = sigmoid(np.dot(result,synapses[i]))\n",
    "\n",
    "    mse = 0.5*np.sum((y_test - result)**2)\n",
    "    print(\"    MSE: \",mse)\n",
    "    if (mse < lowest_mse):\n",
    "        lowest_mse = mse\n",
    "        lowest_synapses = synapses\n",
    "        lowest_syn0 = syn0\n",
    "        lowest_syn1 = syn1\n",
    "        \n",
    "\n",
    "#gen more random data for test set\n",
    "np.random.seed(7)\n",
    "a = np.random.randint(0,2,5) \n",
    "b = np.random.randint(0,2,5)\n",
    "c = a ^ b\n",
    "X, y = splitInputOutput(np.asmatrix([a,b,c]).T)\n",
    "\n",
    "# apply the weights\n",
    "for i in range(len(lowest_synapses)):\n",
    "    if i==0:\n",
    "        result = sigmoid(np.dot(X,lowest_synapses[i]))\n",
    "    else:\n",
    "        result = sigmoid(np.dot(result,lowest_synapses[i]))\n",
    "\n",
    "mse = 0.5*np.sum((y - result)**2)\n",
    "print (\"X_test: \",X)\n",
    "print (\"Y_test: \",y)\n",
    "print (\"Y_pred: \",result)\n",
    "print()\n",
    "print(\"MSE against Test data: \",mse)\n",
    "print(\"Accuracy: \",1-np.sum(np.abs(y-result))/y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.  Now lets load our accute inflamation dataset.  Our dataset was randomized.   It contained 120 rows and we split 80/20 for train&validation(96) / test(24).  We'll use scikit learn's KFold utility class to get our indices for a 5 k-fold cross validation and pick the best model to run our test data against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing K-fold cross validation, splits = 5\n",
      "    MSE:  8.24976336748e-05\n",
      "    MSE:  9.70778642222e-05\n",
      "    MSE:  5.6819720276e-05\n",
      "    MSE:  8.78963118942e-05\n",
      "    MSE:  3.06015703821e-05\n",
      "\n",
      "MSE against Test data:  9.83419583742e-05\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# X,y = getData('data/prepared/dataWithTemp.csv')\n",
    "\n",
    "df = pd.read_csv('data/prepared/dataWithTempRandomized.train.csv',sep=',',names=[\"Temp\", \"Nausea\", \"Lumbar\", \"Pushing\",\"Micturition\",\"Burning\",\"BladderInflamation\"]);\n",
    "df[\"Temp\"] = df.transform(lambda x: x - 37)\n",
    "\n",
    "X,y = splitInputOutput(df.as_matrix())\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=None, shuffle=True)\n",
    "\n",
    "lowest_mse = 1e8 #arbitrary high value\n",
    "lowest_syn0 = []\n",
    "lowest_syn1 = []\n",
    "\n",
    "lowest_synapses = None\n",
    "\n",
    "eta = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "print(\"Performing K-fold cross validation, splits = 5\")\n",
    "# do our cross validation with training data\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    np.random.seed(seed=42)\n",
    "    syn0 = 2*np.random.random((X_train.shape[1],X_train.shape[0])) - 1\n",
    "    syn1 = 2*np.random.random((y_train.shape[0],y_train.shape[1])) - 1\n",
    "    synapses = [syn0, syn1]\n",
    "    \n",
    "    trainNeuralNetArrays(synapses, 0.1, epochs, lambda x: sigmoid(x), lambda x: sigmoid(x)*(1-sigmoid(x)))\n",
    "\n",
    "    for i in range(len(synapses)):\n",
    "        if i==0:\n",
    "            result = sigmoid(np.dot(X_test,synapses[i]))\n",
    "        else:\n",
    "            result = sigmoid(np.dot(result,synapses[i]))\n",
    "#     layer1_transform = sigmoid(np.dot(X_test,syn0))\n",
    "#     result = sigmoid(np.dot(layer1_transform,syn1))\n",
    "    mse = 0.5*np.sum((y_test - result)**2)\n",
    "    print(\"    MSE: \",mse)\n",
    "    if (mse < lowest_mse):\n",
    "        lowest_mse = mse\n",
    "        lowest_synapses = synapses\n",
    "        lowest_syn0 = syn0\n",
    "        lowest_syn1 = syn1\n",
    "        \n",
    "df = pd.read_csv('data/prepared/dataWithTempRandomized.test.csv',sep=',',names=[\"Temp\", \"Nausea\", \"Lumbar\", \"Pushing\",\"Micturition\",\"Burning\",\"BladderInflamation\"]);\n",
    "df[\"Temp\"] = df.transform(lambda x: x - 37)\n",
    "\n",
    "X,y = splitInputOutput(df.as_matrix())\n",
    "\n",
    "for i in range(len(lowest_synapses)):\n",
    "    if i==0:\n",
    "        result = sigmoid(np.dot(X,lowest_synapses[i]))\n",
    "    else:\n",
    "        result = sigmoid(np.dot(result,lowest_synapses[i]))\n",
    "\n",
    "# layer1_transform = sigmoid(np.dot(X,lowest_syn0))\n",
    "# result = sigmoid(np.dot(layer1_transform,lowest_syn1))\n",
    "mse = 0.5*np.sum((y - result)**2)\n",
    "result = np.double(result > 0.5)\n",
    "print()\n",
    "print(\"MSE against Test data: \",mse)\n",
    "print(\"Accuracy: \",1-np.sum(y-result)/y.shape[0])\n",
    "\n",
    "# NOTES: 1 hidden node outperforms accuracy of 2 hidden node of len(X) x len(X) by almost 1.5:1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
