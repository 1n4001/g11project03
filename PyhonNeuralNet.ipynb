{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def getData(filePath):\n",
    "    data = np.genfromtxt(filePath, delimiter=',')\n",
    "    x, y = np.array(data[:,0:-1], dtype=float), np.array(data[:,-1],dtype=int)\n",
    "    y = y.reshape(1,len(y)).T\n",
    "    return x,y\n",
    "\n",
    "def splitInputOutput(data):\n",
    "    x, y = np.array(data[:,0:-1], dtype=float), np.array(data[:,-1],dtype=int)\n",
    "    y = y.reshape(1,len(y)).T\n",
    "    return x,y\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def make_sigmoid_prime(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "# Trivial implementation\n",
    "def trainNeuralNet(synapse0, synapse1, epochs, activator, activator_prime):\n",
    "    for j in range(epochs):\n",
    "        l1 = activator(np.dot(X,synapse0))\n",
    "        l2 = activator(np.dot(l1,synapse1))\n",
    "        l2_delta = (y - l2)*activator_prime(np.dot(l1,synapse1))\n",
    "        l1_delta = l2_delta.dot(synapse1.T) * activator_prime(np.dot(X,synapse0))\n",
    "        synapse1 += l1.T.dot(l2_delta) #adjust our synapses up or down as necessary\n",
    "        synapse0 += X.T.dot(l1_delta)\n",
    "\n",
    "# Now do it with arrays to generalize it a bit more\n",
    "def trainNeuralNetArrays(weights, epochs, activator, activator_prime):\n",
    "    n = len(weights)\n",
    "    layers = [None] * n\n",
    "    deltas = [None] * n\n",
    "    for j in range(epochs):\n",
    "        for i in range(n):\n",
    "            if i == 0: # Push our input into the first weight\n",
    "                layers[i] = activator(np.dot(X,weights[i]))\n",
    "            else: # Push previous layer into current later using weights_i\n",
    "                layers[i] = activator(np.dot(layers[i-1],weights[i]))\n",
    "        for i in reversed(range(n)):\n",
    "            if i == n-1: # The delta closest to our output is (y-t) -- or \"y - layers[i]\" in this case\n",
    "                deltas[i] = (y - layers[i])*activator_prime(np.dot(layers[i-1],weights[i]))\n",
    "            elif i > 0: # While were not the first or last delta use the d_i+1, weights_i+1, layers_i-1, weights_i\n",
    "                deltas[i] = deltas[i+1].dot(weights[i+1].T)*activator_prime(np.dot(layers[i-1],weights[i]))\n",
    "            else: # update d_0 using X instead of one of the layers\n",
    "                deltas[i] = deltas[i+1].dot(weights[i+1].T)*activator_prime(np.dot(X,weights[i]))\n",
    "        for i in reversed(range(n)): # Back propagation time, start at the last weight and move forward\n",
    "            if i != 0:  # testing !=0 so show we backpropogate back to front {else statement}\n",
    "                weights[i] += layers[i-1].T.dot(deltas[i])\n",
    "            else:\n",
    "                weights[i] += X.T.dot(deltas[i])\n",
    "        \n",
    "def transformTestData(x, syn0, syn1, func):\n",
    "    layer1_transform = func(np.dot(x,syn0))\n",
    "    return func(np.dot(layer1_transform,syn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our neural network trainer against a simple dataset: X will contain binary tuples and Y will be the XOR result of rows in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.000477306752279\n",
      "Output of predicted y (2nd and 3rd rows should be close to 1):\n",
      "[[ 0.01869055]\n",
      " [ 0.98941286]\n",
      " [ 0.98293159]\n",
      " [ 0.0142077 ]]\n"
     ]
    }
   ],
   "source": [
    "# trivial dataset\n",
    "X, y = getData('data/prepared/trivial.csv')\n",
    "\n",
    "# X = np.array([ [0,0],[0,1],[1,0],[1,1] ])\n",
    "# y = np.array([[0,1,1,0]]).T # XOR(X)\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "syn0 = 2*np.random.random((X.shape[1],X.shape[0])) - 1\n",
    "syn1 = 2*np.random.random((y.shape[0],y.shape[1])) - 1\n",
    "synapses = [syn0, syn1]\n",
    "epochs = 10000\n",
    "\n",
    "# trainNeuralNet(syn0, syn1, epochs, lambda x: sigmoid(x), lambda x: sigmoid(x)*(1-sigmoid(x)))\n",
    "trainNeuralNetArrays(synapses, epochs, lambda x: sigmoid(x), lambda x: sigmoid(x)*(1-sigmoid(x)))\n",
    "\n",
    "result = transformTestData(X,syn0,syn1,lambda x: sigmoid(x))\n",
    "# layer1_transform = sigmoid(np.dot(X,syn0))\n",
    "# result = sigmoid(np.dot(layer1_transform,syn1))\n",
    "\n",
    "print(\"MSE: \",0.5*np.sum((y - result)**2))\n",
    "print(\"Output of predicted y (2nd and 3rd rows should be close to 1):\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.  Now lets load our accute inflamation dataset.  Our dataset was randomized.   It contained 120 rows and we split 80/20 for train&validation(96) / test(24).  We'll use scikit learn's KFold utility class to get our indices for a 5 k-fold cross validation and pick the best model to run our test data against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing K-fold cross validation, splits = 5\n",
      "    MSE:  3.99999997882\n",
      "    MSE:  0.999999981984\n",
      "    MSE:  2.99999998788\n",
      "    MSE:  1.00000069577\n",
      "    MSE:  1.49999985591\n",
      "\n",
      "MSE against Test data:  1.9999999116\n",
      "Accuracy:  0.833333333333\n"
     ]
    }
   ],
   "source": [
    "# X,y = getData('data/prepared/dataWithTemp.csv')\n",
    "\n",
    "df = pd.read_csv('data/prepared/dataWithTempRandomized.train.csv',sep=',',names=[\"Temp\", \"Nausea\", \"Lumbar\", \"Pushing\",\"Micturition\",\"Burning\",\"BladderInflamation\"]);\n",
    "df[\"Temp\"] = df.transform(lambda x: x - 37)\n",
    "\n",
    "X,y = splitInputOutput(df.as_matrix())\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=None, shuffle=True)\n",
    "\n",
    "lowest_mse = 1e8 #arbitrary high value\n",
    "lowest_syn0 = []\n",
    "lowest_syn1 = []\n",
    "\n",
    "lowest_synapses = None\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "print(\"Performing K-fold cross validation, splits = 5\")\n",
    "# do our cross validation with training data\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    np.random.seed(seed=42)\n",
    "    syn0 = 2*np.random.random((X_train.shape[1],X_train.shape[0])) - 1\n",
    "    syn1 = 2*np.random.random((y_train.shape[0],y_train.shape[1])) - 1\n",
    "    synapses = [syn0, syn1]\n",
    "    \n",
    "    trainNeuralNetArrays(synapses, epochs, lambda x: sigmoid(x), lambda x: sigmoid(x)*(1-sigmoid(x)))\n",
    "\n",
    "    for i in range(len(synapses)):\n",
    "        if i==0:\n",
    "            result = sigmoid(np.dot(X_test,synapses[i]))\n",
    "        else:\n",
    "            result = sigmoid(np.dot(result,synapses[i]))\n",
    "#     layer1_transform = sigmoid(np.dot(X_test,syn0))\n",
    "#     result = sigmoid(np.dot(layer1_transform,syn1))\n",
    "    mse = 0.5*np.sum((y_test - result)**2)\n",
    "    print(\"    MSE: \",mse)\n",
    "    if (mse < lowest_mse):\n",
    "        lowest_mse = mse\n",
    "        lowest_synapses = synapses\n",
    "        lowest_syn0 = syn0\n",
    "        lowest_syn1 = syn1\n",
    "        \n",
    "df = pd.read_csv('data/prepared/dataWithTempRandomized.test.csv',sep=',',names=[\"Temp\", \"Nausea\", \"Lumbar\", \"Pushing\",\"Micturition\",\"Burning\",\"BladderInflamation\"]);\n",
    "df[\"Temp\"] = df.transform(lambda x: x - 37)\n",
    "\n",
    "X,y = splitInputOutput(df.as_matrix())\n",
    "\n",
    "for i in range(len(lowest_synapses)):\n",
    "    if i==0:\n",
    "        result = sigmoid(np.dot(X,lowest_synapses[i]))\n",
    "    else:\n",
    "        result = sigmoid(np.dot(result,lowest_synapses[i]))\n",
    "\n",
    "# layer1_transform = sigmoid(np.dot(X,lowest_syn0))\n",
    "# result = sigmoid(np.dot(layer1_transform,lowest_syn1))\n",
    "mse = 0.5*np.sum((y - result)**2)\n",
    "result = np.double(result > 0.5)\n",
    "print()\n",
    "print(\"MSE against Test data: \",mse)\n",
    "print(\"Accuracy: \",1-np.sum(y-result)/y.shape[0])\n",
    "\n",
    "# NOTES: 1 hidden node outperforms accuracy of 2 hidden node of len(X) x len(X) by almost 1.5:1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
